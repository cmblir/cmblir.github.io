<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="ko" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>[파이썬][머신러닝] 데이터 분석과 머신러닝 - Feature Selection - 성장형 개발자 블로그</title>
<meta name="description" content="교차 검증과 하이퍼 파라미터에 대해">


  <meta name="author" content="You Nicholas">
  
  <meta property="article:author" content="You Nicholas">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="ko">
<meta property="og:site_name" content="성장형 개발자 블로그">
<meta property="og:title" content="[파이썬][머신러닝] 데이터 분석과 머신러닝 - Feature Selection">
<meta property="og:url" content="http://localhost:4000/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D%EA%B3%BC%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/model_selection/">


  <meta property="og:description" content="교차 검증과 하이퍼 파라미터에 대해">







  <meta property="article:published_time" content="2021-12-06T00:00:00+09:00">



  <meta property="article:modified_time" content="2021-12-06T00:00:00+09:00">



  

  


<link rel="canonical" href="http://localhost:4000/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D%EA%B3%BC%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/model_selection/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Yoo Nicholas",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="성장형 개발자 블로그 Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4206652111439335"
     crossorigin="anonymous"></script>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-5218184138518164",
          enable_page_level_ads: true
     });
</script>
<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          성장형 개발자 블로그
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">소개글</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">카테고리</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">태그</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">토글 메뉴</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="https://avatars.githubusercontent.com/u/75519839?v=4" alt="You Nicholas" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">You Nicholas</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>가고 가고 또 가면 <strong>알게되고</strong>, 행하고 행하고 또 행하게 되면 <strong>이루게 된다.</strong></p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">팔로우</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">Republic of Korea</span>
        </li>
      

      
        
          
            <li><a href="godhin:sodlalwl13e@gmail.com" rel="nofollow noopener noreferrer me"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
        
          
        
          
        
          
            <li><a href="https://github.com/godhin" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://instagram.com/cmblir" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i><span class="label">Instagram</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="[파이썬][머신러닝] 데이터 분석과 머신러닝 - Feature Selection">
    <meta itemprop="description" content="교차 검증과 하이퍼 파라미터에 대해">
    <meta itemprop="datePublished" content="2021-12-06T00:00:00+09:00">
    <meta itemprop="dateModified" content="2021-12-06T00:00:00+09:00">

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D%EA%B3%BC%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/model_selection/" class="u-url" itemprop="url">[파이썬][머신러닝] 데이터 분석과 머신러닝 - Feature Selection
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          4 분 소요
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On This Page</h4></header>
              <ul class="toc__menu"><li><a href="#하이퍼-파라미터란">하이퍼 파라미터란?</a><ul><li><a href="#최적의-하이퍼-파라미터-찾기">최적의 하이퍼 파라미터 찾기</a><ul><li><a href="#research">Research</a></li><li><a href="#exhaustive-grid-search">Exhaustive Grid Search</a></li><li><a href="#randomized-search">Randomized Search</a></li><li><a href="#bayesian-search">Bayesian Search</a></li><li><a href="#grid-search-간단하게-구현해보기">Grid Search 간단하게 구현해보기</a></li><li><a href="#결과-확인하기">결과 확인하기</a></li><li><a href="#최적의-하이퍼-파라미터-조합-순위로-확인하기">최적의 하이퍼 파라미터 조합 순위로 확인하기</a></li><li><a href="#hyperopt-bayesian-search">Hyperopt Bayesian Search</a></li><li><a href="#모든-trial-정보-출력하기">모든 trial 정보 출력하기</a></li></ul></li><li><a href="#교차-검증이란">교차 검증이란?</a><ul><li><a href="#교차-검증의-장단점">교차 검증의 장단점</a></li></ul></li><li><a href="#feature-selection">Feature Selection</a><ul><li><a href="#특성-중요도-기반-특성-선택">특성 중요도 기반 특성 선택</a></li><li><a href="#통계-기반-특성-선택">통계 기반 특성 선택</a></li><li><a href="#sklearn의-특성-선택-라이브러리">Sklearn의 특성 선택 라이브러리</a></li><li><a href="#sklearn-regression-문제-특성-선택">Sklearn Regression 문제 특성 선택</a></li></ul></li></ul></li></ul>

            </nav>
          </aside>
        
        <h1 id="하이퍼-파라미터란">하이퍼 파라미터란?</h1>

<blockquote>
  <p>Parameter(매개변수)는 모델 내부에서 데이터로부터 결정되는 변수이다.</p>
  <ul>
    <li>MLM(Machine Learning Mastery)에서 기술한 하이퍼 파라미터는 모델링할 때 직접 세팅해주는 값이라고 말한다. 이는 모델 학습에 나오는 learning rate나 SVM의 C, sigma, KNN의 K값 등등 모델을 세팅할 때 우리가 설정하는 값을 설명한다.
흔히 많은 사람들이 모델 설계를 할 때 값을 조정하는 것을 “하이퍼 파라미터를 조정한다.”라고 말한다.</li>
  </ul>
</blockquote>

<h2 id="최적의-하이퍼-파라미터-찾기">최적의 하이퍼 파라미터 찾기</h2>

<h3 id="research">Research</h3>

<p>모델을 튜닝하는 방법에는 다양한 방법이 존재한다. 그 중 직접 튜닝하는 방법은 여러가지 지식또는 기법을 통해서 개발자가 비교하면서 찾는 방법으로 가장 기초적인 방식이다.</p>

<h3 id="exhaustive-grid-search">Exhaustive Grid Search</h3>

<p>검증을 목표로 하는 하이퍼 파라미터의 범위 내에서 모든 조합에 대해 모델을 학습하고, 그 중 가장 좋은 metric 조합을 선택한다.</p>

<blockquote>
  <p>시간적인 여유가 있다면 굉장히 좋겠지만, 조합의 수가 굉장히 많아서 비효율적이다.</p>
</blockquote>

<h3 id="randomized-search">Randomized Search</h3>

<p>검증을 목표로 하는 하이퍼 파라미터의 범위 내에서 랜덤하게 조합을 선택하여, 그 중 가장 좋은 metric 조합을 선택하는 것이다.</p>

<p>탐색 횟수를 지정해주기에 하이퍼 파라미터 수가 많고 범위가 넓더라도 탐색이 가능하다.</p>

<blockquote>
  <p>랜덤하게 선택하기 때문에 이상적인 조합을 찾기가 쉽지 않다.</p>
</blockquote>

<h3 id="bayesian-search">Bayesian Search</h3>

<p>검증을 목표로 하는 하이퍼 파라미터의 범위 내에서 이전 조합중 가장 성능이 잘 나온 조합을 중심으로 탐색하고 선택하여, 그 중 가장 좋은 metric 조합을 선택하는 것이다.</p>

<p>위 2가지 탐색기법중에서 가장 똑똑하고 효율적으로 하이퍼 파라미터 조합을 찾을 수 이;ㅆ다.</p>

<h3 id="grid-search-간단하게-구현해보기">Grid Search 간단하게 구현해보기</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">category_encoders</span> <span class="kn">import</span> <span class="n">OrdinalEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>

<span class="c1"># 간단하게 파이프라인을 형성해준다.
</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">OrdinalEncoder</span><span class="p">(),</span>
    <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s">"median"</span><span class="p">),</span>
    <span class="n">XGBClassifier</span><span class="p">(</span>
        <span class="n">objective</span><span class="o">=</span><span class="s">"binary:logistic"</span><span class="p">,</span>
        <span class="n">eval_metric</span><span class="o">=</span><span class="s">"error"</span><span class="p">,</span>
        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">use_label_encoder</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="p">),</span>
<span class="p">)</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"xgbclassifier__max_depth"</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span>
    <span class="s">"xgbclassifier__min_child_weight"</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
    <span class="s">"xgbclassifier__colsample_bytree"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
<span class="p">}</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="c1"># Sklearn의 GridSearchCV를 활용한다. 
</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">"roc_auc"</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="c1"># 위의 지정해준 파라미터를 기준으로 Grid Search를 시작한다.
</span>
<span class="n">grid_search</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="결과-확인하기">결과 확인하기</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"최적의 하이퍼파라미터: "</span><span class="p">,</span> <span class="n">grid_search</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"최적의 AUC: "</span><span class="p">,</span> <span class="n">grid_search</span><span class="p">.</span><span class="n">best_score_</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="최적의-하이퍼-파라미터-조합-순위로-확인하기">최적의 하이퍼 파라미터 조합 순위로 확인하기</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">grid_search</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s">"rank_test_score"</span><span class="p">).</span><span class="n">T</span>
</code></pre></div></div>

<h3 id="hyperopt-bayesian-search">Hyperopt Bayesian Search</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">hyperopt</span> <span class="kn">import</span> <span class="n">hp</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"simpleimputer__strategy"</span><span class="p">:</span> <span class="n">hp</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="s">"strategy"</span><span class="p">,</span> <span class="p">[</span><span class="s">"median"</span><span class="p">,</span> <span class="s">"mean"</span><span class="p">]),</span>
    <span class="s">"xgbclassifier__max_depth"</span><span class="p">:</span> <span class="n">hp</span><span class="p">.</span><span class="n">quniform</span><span class="p">(</span><span class="s">"max_depth"</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
    <span class="s">"xgbclassifier__min_child_weight"</span><span class="p">:</span> <span class="n">hp</span><span class="p">.</span><span class="n">quniform</span><span class="p">(</span><span class="s">"min_child_weight"</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
    <span class="s">"xgbclassifier__colsample_bytree"</span><span class="p">:</span> <span class="n">hp</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="s">"colsample_bytree"</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
<span class="p">}</span>

<span class="kn">from</span> <span class="nn">hyperopt</span> <span class="kn">import</span> <span class="n">fmin</span><span class="p">,</span> <span class="n">tpe</span><span class="p">,</span> <span class="n">Trials</span><span class="p">,</span> <span class="n">STATUS_OK</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">fit_eval</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
  <span class="n">pipe</span> <span class="o">=</span> <span class="n">get_pipe</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
  <span class="n">score</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s">"roc_auc"</span><span class="p">)</span>

  <span class="k">return</span> <span class="p">{</span><span class="s">"loss"</span> <span class="p">:</span> <span class="o">-</span> <span class="n">avg_cv_score</span><span class="p">,</span> <span class="s">"status"</span> <span class="p">:</span> <span class="n">STARUS_OK</span><span class="p">}</span>
  <span class="c1"># rou_auc 값이 클ㄹ수록 좋은 metric이므로, hyperopt.fmin이 rou_auc 최대화도록 하기 위해 -부호를 붙여 반환한다.
</span>

<span class="n">trials</span> <span class="o">=</span> <span class="p">(</span><span class="n">Trials</span><span class="p">())</span>

<span class="n">best_params</span> <span class="o">=</span> <span class="n">fmin</span><span class="p">(</span><span class="n">fn</span> <span class="o">=</span> <span class="n">fit_and_eval</span><span class="p">,</span> <span class="n">trials</span> <span class="o">=</span> <span class="n">trials</span><span class="p">,</span> <span class="n">space</span> <span class="o">=</span> <span class="n">params</span><span class="p">,</span> <span class="n">algo</span> <span class="o">=</span> <span class="n">tpe</span><span class="p">.</span><span class="n">suggest</span><span class="p">,</span> <span class="n">max_evals</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="모든-trial-정보-출력하기">모든 trial 정보 출력하기</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trials</span><span class="p">.</span><span class="n">trials</span>
</code></pre></div></div>

<h2 id="교차-검증이란">교차 검증이란?</h2>

<blockquote>
  <p>학습 시킨 모델을 검증 데이터를 사용하는 방식을 통해서 검증하는 것을 의미한다.</p>
  <ul>
    <li>우리는 흔히 모델을 학습 시킨 이후에 2가지로 나눠서 모델의 성능을 측정하게 된다.
      <ul>
        <li>학습 데이터 (Train)</li>
        <li>시험 데이터 (Test)</li>
      </ul>
    </li>
  </ul>
</blockquote>

<ul>
  <li>위의 방식으로 측정을 하게 되도 무관하나, 시험 데이터에 과적합을 하게 되거나 실 데이터를 가져와서 원하는 결과를 가지고 오지 못할 가능성이 있다.</li>
</ul>

<p>그래서 <em>교차 검증</em>을 통해서 3가지로 나눠서 검증을 한다.</p>
<ul>
  <li>학습 데이터 (Train)</li>
  <li><strong>검증 데이터 (Validation)</strong></li>
  <li>시험 데이터 (Test)</li>
</ul>

<h3 id="교차-검증의-장단점">교차 검증의 장단점</h3>

<ol>
  <li>장점
    <ul>
      <li>데이터의 활용도 증가
        <ul>
          <li>성능향상으로 이어진다.</li>
        </ul>
      </li>
      <li>과적합
        <ul>
          <li>데이터를 나눠서 사용하게 되기에 시험 데이터에 과적합되는 현상을 방지할 수 있다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>단점
    <ul>
      <li>학습 시간 증가
        <ul>
          <li>iteration 증가로 인해서 시간이 오래 걸릴 가능성이 있다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h2 id="feature-selection">Feature Selection</h2>

<blockquote>
  <p>모델의 분류 정확도를 향상시키기 위해, 원본 데이터에서 가장 좋은 성능을 보여줄 수 있는 데이터의 부분집합 (Subset)을 찾는 방법이다.</p>
</blockquote>

<p>결론적으로 특성 중에서 훈련에 가장 유용한 특성을 선택하는 것을 말한다.</p>

<h3 id="특성-중요도-기반-특성-선택">특성 중요도 기반 특성 선택</h3>

<ol>
  <li>Check Score</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># AUC 점수를 체크한다.
</span><span class="k">print</span><span class="p">(</span><span class="s">"Validation AUC: "</span><span class="p">,</span> <span class="n">pipe</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">))</span>
</code></pre></div></div>

<ol>
  <li>Feature Selection</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 특성 중요도를 시각화하여 특성 중요도가 낮은 몇몇 특성들을 확인한다.
</span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">feature_importances</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
    <span class="nb">zip</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">pipe</span><span class="p">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s">"xgbclassifier"</span><span class="p">].</span><span class="n">feature_importances_</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">feature_importances</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">feature_importances</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">120</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">barh</span><span class="p">(</span><span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">feature_importances</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="mf">0.015</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"red"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</code></pre></div></div>

<ol>
  <li>Feature Drop 
불필요한 특성들은 오히려 학습에 방해가 되므로 제외하고 재학습을 진행해준다.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">features_selected</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.015</span><span class="p">,</span> <span class="n">feature_importances</span><span class="p">))</span>

<span class="c1"># 0.015 중요도 미만의 값들을 선택해준다.
</span>
<span class="n">selected_feature_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">features_selected</span><span class="p">))</span>
</code></pre></div></div>

<ol>
  <li>re-Check Score</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">selected_feature_names</span><span class="p">]</span>
<span class="n">X_val_selected</span> <span class="o">=</span> <span class="n">X_val</span><span class="p">[</span><span class="n">selected_feature_names</span><span class="p">]</span>

<span class="n">pipe</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Validation AUC: "</span><span class="p">,</span> <span class="n">pipe</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_val_selected</span><span class="p">,</span> <span class="n">y_val</span><span class="p">))</span>
</code></pre></div></div>

<h3 id="통계-기반-특성-선택">통계 기반 특성 선택</h3>
<ol>
  <li>피어슨 상관계수
    <blockquote>
      <p>공분사산 / 표준편차의 제곱으로, 등간척도(간격척도)나 비례척도(비율척도)의 데이터에서 두 변수의 공분산(Covariance)을 각각의 표준 편차의 곱으로 나눈 값이다.</p>
    </blockquote>
  </li>
</ol>

<ul>
  <li>표준 피어슨의 상관계수 r 로부터 표본 결정계수 r^2을 얻을 수 있다.</li>
  <li>모집단 피어슨의 상관계수 p 로부터 모집단 결정계수 p^2을 얻을 수 있다.</li>
  <li><em>numpy</em>로 간단하게 구할 수 있다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">3</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># 두 특성이 선형 관계는 아니지만 단조 관계일 때를 확인
</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s">"."</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Pearson Corrcoef:"</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Spearman Corrcoef:"</span><span class="p">,</span> <span class="n">spearmanr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</code></pre></div></div>

<ol>
  <li>스피어만 상관계수
    <blockquote>
      <p>두 변수의 순위 사이의 통계적 의존성을 측정하는 비모수적인 척도이다.</p>
    </blockquote>
  </li>
</ol>

<ul>
  <li>두 변수 간의 스피어만 상관 계수는 두 변수의 순위 값 사이의 피어슨 상관 계수와 같다.</li>
  <li><em>Scipy</em>로 간단하게 구할 수 있다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">spearmanr</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">7</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># 두 특성이 선형 관계일 때 pearson, spearman corrcoef 값을 확인
</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s">"."</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Pearson Corrcoef:"</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Spearman Corrcoef:"</span><span class="p">,</span> <span class="n">spearmanr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</code></pre></div></div>

<h3 id="sklearn의-특성-선택-라이브러리">Sklearn의 특성 선택 라이브러리</h3>
<blockquote>
  <p>sklearn.feature_selection.SelectKBest</p>
</blockquote>

<p><strong>통계량 옵션 선택</strong></p>

<ul>
  <li>Classification Options
    <ol>
      <li>f_calssif</li>
      <li>mutual_info_classif</li>
      <li>chi2</li>
    </ol>
  </li>
  <li>Regression Options
    <ol>
      <li>f_regression</li>
      <li>mutual_info_regression</li>
    </ol>
  </li>
</ul>

<h3 id="sklearn-regression-문제-특성-선택">Sklearn Regression 문제 특성 선택</h3>
<p>위에서</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">category_encoders</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="n">enc</span> <span class="o">=</span> <span class="n">OrdinalEncoder</span><span class="p">()</span>
<span class="n">imp</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">()</span>

<span class="n">X_train_encoded</span> <span class="o">=</span> <span class="n">enc</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_train_imputed</span> <span class="o">=</span> <span class="n">imp</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_encoded</span><span class="p">)</span>

<span class="n">X_val_encoded</span> <span class="o">=</span> <span class="n">enc</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
<span class="n">X_val_imputed</span> <span class="o">=</span> <span class="n">imp</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_val_encoded</span><span class="p">)</span>
<span class="c1"># 회귀 문제이므로 간단하게 원-핫 인코딩을 진행해준다.
</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">mutual_info_classif</span>
<span class="c1"># 위에서 언급한 Sklearn의 SelectKBest와 mutual_info_classif 를 사용해서 간단하게 문제의 특성을 선택해준다.
</span>
<span class="n">selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">score_func</span><span class="o">=</span><span class="n">mutual_info_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">selector</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_imputed</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">X_val_selected</span> <span class="o">=</span> <span class="n">selector</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_val_imputed</span><span class="p">)</span>


<span class="k">print</span><span class="p">(</span><span class="s">"Feature Selection: "</span><span class="p">,</span> <span class="n">X_train_encoded</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="n">selector</span><span class="p">.</span><span class="n">get_support</span><span class="p">()].</span><span class="n">tolist</span><span class="p">())</span>
</code></pre></div></div>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> 태그: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D" class="page__taxonomy-item p-category" rel="tag">데이터 분석</a><span class="sep">, </span>
    
      <a href="/tags/#%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D" class="page__taxonomy-item p-category" rel="tag">머신러닝</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> 카테고리: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D%EA%B3%BC-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D" class="page__taxonomy-item p-category" rel="tag">데이터 분석과 머신러닝</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> 업데이트:</strong> <time class="dt-published" datetime="2021-12-06">December 6, 2021</time></p>

      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">공유하기</h4>
  

  <a href="https://twitter.com/intent/tweet?text=%5B%ED%8C%8C%EC%9D%B4%EC%8D%AC%5D%5B%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%5D+%EB%8D%B0%EC%9D%B4%ED%84%B0+%EB%B6%84%EC%84%9D%EA%B3%BC+%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D+-+Feature+Selection%20http%3A%2F%2Flocalhost%3A4000%2F%25EB%258D%25B0%25EC%259D%25B4%25ED%2584%25B0%2520%25EB%25B6%2584%25EC%2584%259D%25EA%25B3%25BC%2520%25EB%25A8%25B8%25EC%258B%25A0%25EB%259F%25AC%25EB%258B%259D%2Fmodel_selection%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2F%25EB%258D%25B0%25EC%259D%25B4%25ED%2584%25B0%2520%25EB%25B6%2584%25EC%2584%259D%25EA%25B3%25BC%2520%25EB%25A8%25B8%25EC%258B%25A0%25EB%259F%25AC%25EB%258B%259D%2Fmodel_selection%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2F%25EB%258D%25B0%25EC%259D%25B4%25ED%2584%25B0%2520%25EB%25B6%2584%25EC%2584%259D%25EA%25B3%25BC%2520%25EB%25A8%25B8%25EC%258B%25A0%25EB%259F%25AC%25EB%258B%259D%2Fmodel_selection%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D%EA%B3%BC%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/preprocessing/" class="pagination--pager" title="[파이썬][머신러닝] 데이터 분석과 머신러닝 - Processing
">이전</a>
    
    
      <a href="/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0%20%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94%20%EB%94%A5%EB%9F%AC%EB%8B%9D/Deep-learning-from-bottom-up-(%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D)/" class="pagination--pager" title="[파이썬][딥러닝] 밑바닥부터 시작하는 딥러닝
">다음</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h2 class="page__related-title">참고</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/%EA%B9%83/github_commit_rules/" rel="permalink">[Github] 깃허브 커밋 Rule
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          4 분 소요
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">알고 하는 커밋 법칙
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/%EC%BD%94%EB%94%A9%ED%85%8C%EC%8A%A4%ED%8A%B8/118666/" rel="permalink">[파이썬][프로그래머스] 성격 유형 검사하기
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          5 분 소요
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">프로그래머스 성격 유형 검사하기 문제 풀이
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4/ORM/" rel="permalink">[데이터베이스] 객체 관계형 데이터베이스 매핑
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          1 분 소요
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">ORM에 대해서 알아보자
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%88%98%EC%A7%91/faker_user/" rel="permalink">[파이썬][라이브러리] 모델 학습에 필요한 가짜 유저 정보 만들기
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          2 분 소요
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Faker 라이브러리 사용하기
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4206652111439335"
     crossorigin="anonymous"></script>
    <div align="center" style="margin: 1em 0;">
    <ins class="adsbygoogle"
    style="display:block; border-bottom: initial;"
    data-ad-client="ca-pub-9089895411733030"
    data-ad-format="auto"></ins>
  </div>
  <script>
  (adsbygoogle = window.adsbygoogle || []).push({});
  </script>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4206652111439335"
     crossorigin="anonymous"></script>
     <div align="center" style="margin: 1em 0;">
        <ins class="adsbygoogle"
        style="display:block; border-bottom: initial;"
        data-ad-client="ca-pub-9089895411733030"
        data-ad-format="auto"></ins>
    </div>
    <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>팔로우:</strong></li>
    

    
      
        
          <li><a href="godhin:sodlalwl13e@gmail.com" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email</a></li>
        
      
        
      
        
      
        
      
        
          <li><a href="https://github.com/godhin" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://instagram.com/cmblir" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i> Instagram</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> 피드</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2022 Yoo Nicholas. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
